%!TEX root = ../main.tex

\chapter*{结\quad 论}
\phantomsection
\addcontentsline{toc}{chapter}{结论}

互联网具有快速传播和广泛覆盖的特性，对互联网舆情进行有效监控是必不可少的。
在一个聚焦于新闻、博客和论坛的多通道爬虫系统中，
海量异构、持续变化的特点，给大范围舆情监控带来困难，
迫切需要一种高度自动化的Web信息抽取方式，以降低系统扩展和维护的成本。

本文的主要工作成果如下：

（1）针对新闻、博客这类正文集中的网站，提出了一种基于有效字符的Web内容抽取方法
CEVC（Content Extraction via Valid Characters）。
该方法主要基于这样的观察，网页中不属于链接并包含停止词的文本，更有可能是主要内容。
定义这样的字符为有效字符，根据它们在DOM树中的分布，逐级确定正文区域，并最终提取正文。
与之前的算法CETR（基于文本标签比）、CETD（基于文本密度）
和CEPR（基于文本标签路径比）进行了比较。
实验结果表明，CEVC算法在各项评价指标上都优于CETR和CEPR，
虽然抽取性能和CETD相当，但在预处理阶段依赖更小，适用性更强。

（2）针对论坛网站，提出了一种论坛帖子抽取算法PEAN（Post Extraction via Anchor Nodes）。
该方法利用论坛帖子中普遍存在的发帖时间信息作为锚节点，
根据它们在DOM树中的分布情况，定位论坛帖子集中的区域，并结合树匹配算法，
在候选子树中过滤噪声，最终抽取出论坛帖子。
实验结果表明，PEAN相比于MiBAT在召回率指标上有大幅度提升，
总体F\textsubscript{1}指标也优于MiBAT。

（3）为了验证本文提出的信息抽取算法的实际效果，
根据实际需求设计并实现了一个针对新闻的应用实例——Web新闻聚合系统。
介绍了系统架构和工作流程，并对系统模块和关键技术做了详细阐述，
最后对系统运行效果进行评估。
系统从RSS、元搜索和一般新闻网站三个信息来源采集新闻，
通过模板无关的抽取技术整合了各个渠道的差异，使人工成本限制在新闻列表解析中。

为了进一步提高多通道爬虫系统的自动化采集能力，在以下几个方面还值得继续深入研究：

（1）研究新闻、博客采集源的自动扩展，进一步减少人工参与。

（2）在抽取论坛帖子的基础上，进一步研究作者、发帖内容等元信息的抽取。

（3）研究通用论坛的爬行策略，从论坛中自动解析板块入口和帖子入口。
